{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Jitender Singh Virk ||\n",
    "Date created: 25 Dec 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_location = \"C:\\\\Users\\\\Virksaab\\\\Desktop\\\\AI\\\\datasets_for_code_in_repos\\\\char74k_dataset\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global constants describing the data set.\n",
    "NUM_CLASSES = 62\n",
    "IMAGE_SIZE = 64\n",
    "IMAGE_PIXELS = IMAGE_SIZE * IMAGE_SIZE * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "batch_size = 1\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read tfrecords files in batch\n",
    "def read_tfrecords_in_batch(filename, batch_size=64, num_epochs=None, shuffle=False):\n",
    "    # Create a queue\n",
    "    filename_queue = tf.train.string_input_producer([filename], num_epochs=num_epochs, shuffle=shuffle)\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(serialized_example, features={'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "                                                                     'label': tf.FixedLenFeature([], tf.int64)})\n",
    "    # Convert from a scalar string tensor (whose single string has\n",
    "    # length IMAGE_PIXELS) to a uint8 tensor with shape [IMAGE_PIXELS]\n",
    "    image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "    image.set_shape([IMAGE_PIXELS])\n",
    "    # Convert label from a scalar uint8 tensor to an int32 scalar.\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    # Get data in batch\n",
    "    image_batch, labels_batch = tf.train.batch([image, label], batch_size=batch_size, num_threads=10, capacity=32)\n",
    "    return image_batch, labels_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = data_location+\"train.tfrecords\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Get data in batch(put this line before queue runners and initialization ops)\n",
    "    image_batch, labels_batch = read_tfrecords_in_batch(filename, batch_size=batch_size, num_epochs=epochs, shuffle=False)\n",
    "    \n",
    "    # Op for initializing the variables.\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    # Set coordinator and start queue runner\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    try:\n",
    "        batch_no = 0\n",
    "        while not coord.should_stop():\n",
    "            batch_no += 1\n",
    "            # Run training steps or whatever\n",
    "            data = sess.run([image_batch, labels_batch])\n",
    "            #print(\"Batch number:\", batch_no)\n",
    "            if batch_no % 100 == 0:\n",
    "                img = data[0].reshape(64, 64, 3)\n",
    "                plt.imshow(img)\n",
    "                plt.show()\n",
    "            print(batch_no)\n",
    "                #print(\"X:\", data[0].shape, \" Y:\", data[1].shape)\n",
    "\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done training -- epoch limit reached')\n",
    "\n",
    "    finally:\n",
    "        # When done, ask the threads to stop.\n",
    "        coord.request_stop()\n",
    "\n",
    "\n",
    "    # Wait for threads to finish.\n",
    "    coord.join(threads)\n",
    "    sess.close() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Copyright Â© 2017, Jitender Singh Virk\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
